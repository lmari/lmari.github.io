{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Un'introduzione operativa agli LLM\n",
    "### Con accesso a un LLM locale attraverso un server di API\n",
    "\n",
    "(Luca, febbraio 2024; ambiente virtuale locale; installato `openai`)\n",
    "\n",
    "Al momento il sistema più semplice per eseguire sul proprio computer un LLM e accedere a esso attraverso una API è **LM Studio**:\n",
    "* scaricare da https://lmstudio.ai e installare LM Studio\n",
    "* eseguire LM Studio e seguendo le indicazioni nel programma:\n",
    "    * scaricare dalla rete un LLM (per esempio **TheBloke mistral openorca 7B Q4_0 gguf**)\n",
    "    * caricare il LLM\n",
    "    * mettere in esecuzione il server\n",
    "\n",
    "Occorre ora creare un ambiente di lavoro Python, supponiamo con **VSCode**:\n",
    "* installare un interprete Python\n",
    "* scaricare da https://code.visualstudio.com/download e installare VSCode\n",
    "* eseguire VSCode e attivare le estensioni per Python e Jupyter\n",
    "* ancora in VSCode:\n",
    "    * creare una cartella di lavoro (per esempio chiamandola `intro`) e renderla la cartella corrente:  \n",
    "    * creare un ambiente virtuale locale Python (Select Kernel | Python Environments | Create Python Environment):  \n",
    "    * installare il modulo Python richiesto, eseguendo dal terminale:  \n",
    "        `pip install openai`\n",
    "    * copiare nella cartella questo notebook e il file `utils.py` e aprire il notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per prima cosa, importiamo il modulo che contiene le funzioni per consentire un accesso \"di alto livello\" al LLM in esecuzione in LM Studio e quindi attiviamo la connessione al LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import llm\n",
    "llm = llm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A questo punto siamo già pronti per fare una domanda al LLM, ricevere e visualizzare la risposta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-xqyiemyz84k9ira6zjp2su', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"The main features of the Bayesian interpretation of probability include updating beliefs based on new evidence using Bayes' theorem, considering personal subjective probabilities, and representing uncertainty through the use of probability distributions for uncertain variables.\", role='assistant', function_call=None, tool_calls=None))], created=1707581132, model='/home/lucamari/.local/share/nomic.ai/GPT4All/TheBloke/mistral-7b-openorca.Q4_0/mistral-7b-openorca.Q4_0.gguf', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=43, prompt_tokens=412, total_tokens=455))\n"
     ]
    }
   ],
   "source": [
    "prompt = \"What are the main features of the Bayesian interpretation of probability? Please answer in one or two sentences.\"\n",
    "answer = llm.request(prompt)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La risposta non è molto leggibile, perché è un oggetto Python. Per curiosità, ne possiamo visualizzare il contenuto come un oggetto JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-xqyiemyz84k9ira6zjp2su\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"message\": {\n",
      "        \"content\": \"The main features of the Bayesian interpretation of probability include updating beliefs based on new evidence using Bayes' theorem, considering personal subjective probabilities, and representing uncertainty through the use of probability distributions for uncertain variables.\",\n",
      "        \"role\": \"assistant\",\n",
      "        \"function_call\": null,\n",
      "        \"tool_calls\": null\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1707581132,\n",
      "  \"model\": \"/home/lucamari/.local/share/nomic.ai/GPT4All/TheBloke/mistral-7b-openorca.Q4_0/mistral-7b-openorca.Q4_0.gguf\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"system_fingerprint\": null,\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 43,\n",
      "    \"prompt_tokens\": 412,\n",
      "    \"total_tokens\": 455\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from utils import jprint\n",
    "jprint(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per visualizzare solo il testo della risposta, usiamo la funzione `bprint` dal modulo `utils`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The main features of the Bayesian interpretation of probability include updating beliefs based on\n",
      "new evidence using Bayes' theorem, considering personal subjective probabilities, and representing\n",
      "uncertainty through the use of probability distributions for uncertain variables.\n"
     ]
    }
   ],
   "source": [
    "from utils import bprint\n",
    "bprint(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ancora meglio, possiamo attivare la funzione per visualizzare i token progressivamente, mano a mano che vengono generati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The main features of the Bayesian interpretation of probability involve updating beliefs about unknown\n",
      " quantities based on new evidence, representing subjective knowledge using a prior distribution, and incorpor\n",
      "ating any information available to revise these beliefs through Bayes' theorem, leading to a posterior\n",
      " distribution that reflects updated knowledge."
     ]
    }
   ],
   "source": [
    "from utils import aprint\n",
    "aprint(llm.request(prompt, stream=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
