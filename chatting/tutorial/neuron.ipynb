{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L'approssimazione di una funzione lineare mediante un singolo neurone a comportamento lineare\n",
    "\n",
    "Luca Mari, settembre 2024  \n",
    "\n",
    "Quest'opera è distribuita con <a href=\"http://creativecommons.org/licenses/by-nc-sa/4.0\" target=\"_blank\">Licenza Creative Commons Attribuzione - Non commerciale - Condividi allo stesso modo 4.0 Internazionale</a>.  \n",
    "<img src=\"https://creativecommons.it/chapterIT/wp-content/uploads/2021/01/by-nc-sa.eu_.png\" width=\"100\">\n",
    "\n",
    "**Obiettivo**: comprendere, a partire da un esempio concreto, che una rete neurale deve includere degli elementi non lineari per poter approssimare appropriatamente anche delle semplici funzioni non lineari.  \n",
    "**Precompetenze**: basi di Python; almeno qualche idea di analisi matematica.\n",
    "\n",
    "> Per eseguire questo notebook, supponiamo con VSCode, occorre:\n",
    "> * installare un interprete Python\n",
    "> * scaricare da https://code.visualstudio.com/download e installare VSCode\n",
    "> * eseguire VSCode e attivare le estensioni per Python e Jupyter\n",
    "> * ancora in VSCode:\n",
    ">     * creare una cartella di lavoro e renderla la cartella corrente\n",
    ">     * copiare nella cartella il file di questa attività: [neuron.ipynb](neuron.ipynb)\n",
    ">     * aprire il notebook `neuron.ipynb`\n",
    ">     * creare un ambiente virtuale locale Python (Select Kernel | Python Environments | Create Python Environment | Venv, e scegliere un interprete Python):\n",
    ">     * installare il modulo Python richiesto, eseguendo dal terminale:  \n",
    ">         `pip install torch`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una rete neurale è l'implementazione di una funzione parametrica $Y = f(X; \\theta)$, e può essere intesa come uno strumento di approssimazione di funzioni $F(X)$ date: attraverso un opportuno addestramento, si trovano i valori appropriati dei parametri $\\theta$ in modo che $f(X; \\theta) \\approx F(X)$.\n",
    "\n",
    "Quest'idea venne sviluppata inizialmente assumendo che i componenti elementari di una rete -- i suoi neuroni -- avessero un comportamento lineare:  \n",
    "\n",
    "![rete](neuron.drawio.svg)  \n",
    "nel caso di due input.\n",
    "\n",
    "La situazione più semplice è ovviamente quella di una rete costituita da un solo neurone. Facciamo qualche prova.\n",
    "\n",
    "Per costruire e operare sulla rete useremo `PyTorch`: importiamo perciò i moduli Python che saranno necessari e verifichiamo se è disponibile una GPU per eseguire la rete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Costruiamo la rete usando `PyTorch` (il codice ha un po' di dettagli tecnici, non necessariamente importanti: i commenti potrebbero essere comunque utili) e visualizziamo i valori dei suoi parametri, che inizialmente sono casuali."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I parametri della rete sono:\n",
      "neuron.weight tensor([[-0.5119,  0.2495]], device='cuda:0')\n",
      "neuron.bias tensor([-0.1720], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "class OneNeuron(nn.Module):\n",
    "    def __init__(self, device):\n",
    "        super(OneNeuron, self).__init__()\n",
    "        self.neuron = nn.Linear(2, 1)\n",
    "\n",
    "        self.loss = nn.MSELoss()        # funzione di errore: Mean Squared Error\n",
    "        self.optimizer = optim.SGD(self.parameters(), lr=0.01) # ottimizzatore: Stochastic Gradient Descent\n",
    "        self.device = device\n",
    "        self.to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.neuron(x)\n",
    "        return x\n",
    "\n",
    "    def set_learning_rate(self, learning_rate):\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            param_group['lr'] = learning_rate        \n",
    "\n",
    "    def train(self, x, y, epochs, repeat):\n",
    "        print(f'\\n*** Addestramento ***\\nepoca\\terrore (su {device})')\n",
    "        for epoch in range(epochs):\n",
    "            self.optimizer.zero_grad()  # azzera i gradienti\n",
    "            output = self(x)            # calcola l'output\n",
    "            loss = self.loss(output, y) # calcola la funzione di errore\n",
    "            loss.backward()             # calcola i gradienti\n",
    "            self.optimizer.step()       # aggiorna i valori dei parametri\n",
    "            if (epoch+1) % repeat == 0:\n",
    "                print(f'{epoch+1}\\t{loss.item():.3f}')\n",
    "\n",
    "    def predict(self, examples, fun):\n",
    "        print('\\n*** Inferenza ***')\n",
    "        x_test = examples\n",
    "        y_test = self(x_test)           # calcola la previsione\n",
    "        y_true = self.calc_fun(fun, x_test)\n",
    "        print('x1\\tx2\\ty\\ty prev\\terrore')\n",
    "        for i in range(x_test.size(0)):\n",
    "            x1, x2 = x_test[i][0].item(), x_test[i][1].item()\n",
    "            y, y_hat = y_true[i].item(), y_test[i].item()\n",
    "            print(f'{x1:.2f}\\t{x2:.2f}\\t{y:.2f}\\t{y_hat:.2f}\\t{y - y_hat:.2f}')\n",
    "        print(f'Errore quadratico medio: {torch.mean((y_test - y_true)**2):.5f}')\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for layer in self.children():\n",
    "            if hasattr(layer, 'reset_parameters'):\n",
    "                layer.reset_parameters()\n",
    "\n",
    "    def print_parameters(self):\n",
    "        for name, param in self.named_parameters():\n",
    "            print(name, param.data)\n",
    "\n",
    "    def calc_fun(self, fun, X):\n",
    "        return fun(X[:, 0], X[:, 1]).view(-1, 1).to(self.device)\n",
    "\n",
    "\n",
    "model = OneNeuron(device)\n",
    "print('I parametri della rete sono:'); model.print_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Costruiamo il training set, prima di tutto negli input (_features_, _covariates_) come un certo numero di coppie di numeri casuali."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def examples(n): return (10 * torch.rand(n, 2) - 5).to(device) # genera n esempi nella forma ognuno di una coppia di numeri casuali tra -5 e 5\n",
    "num_examples = 100                      # numero di esempi per il training set\n",
    "X = examples(num_examples)              # calcola i valori degli esempi: input del training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scegliamo la funzione, dunque a due argomenti, da approssimare. Essendo un caso di _supervised learning_, calcoliamo la funzione per tutte le coppie del training set e aggiungiamo il risultato al training set stesso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun(x1, x2): return (x1 + x2) / 2   # funzione da approssimare, in questo caso la media tra due numeri\n",
    "Y = model.calc_fun(fun, X)              # calcola il valore della funzione per ogni esempio: output del training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Già ora possiamo mettere in funzione la rete, su un certo numero di esempi che costituiscono dunque un test set, ma ovviamente il risultato non sarà in alcun modo accurato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** Inferenza ***\n",
      "x1\tx2\ty\ty prev\terrore\n",
      "2.65\t-0.36\t1.14\t-1.62\t2.76\n",
      "-4.98\t3.88\t-0.55\t3.34\t-3.89\n",
      "2.72\t-3.83\t-0.56\t-2.52\t1.96\n",
      "0.47\t1.30\t0.89\t-0.09\t0.97\n",
      "-2.23\t-2.57\t-2.40\t0.33\t-2.73\n",
      "2.97\t4.53\t3.75\t-0.56\t4.31\n",
      "3.15\t3.71\t3.43\t-0.86\t4.29\n",
      "-1.08\t3.34\t1.13\t1.21\t-0.08\n",
      "-3.41\t0.94\t-1.24\t1.81\t-3.05\n",
      "-4.87\t3.07\t-0.90\t3.09\t-3.99\n",
      "Errore quadratico medio: 9.72123\n"
     ]
    }
   ],
   "source": [
    "model.predict(examples(10), fun)        # inferenza prima dell'addestramento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Addestriamo allora la rete, dopo aver assegnato valori opportuni ai due iperparametri fondamentali:  \n",
    "-- il numero di volte in cui il processo di addestramento viene ripetuto, e  \n",
    "-- la velocità di apprendimento (_learning rate_)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** Addestramento ***\n",
      "epoca\terrore (su cuda)\n",
      "10\t0.195\n",
      "20\t0.088\n",
      "30\t0.040\n",
      "40\t0.018\n",
      "50\t0.008\n",
      "60\t0.004\n",
      "70\t0.002\n",
      "80\t0.001\n",
      "90\t0.000\n",
      "100\t0.000\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100                        # numero di ripetizioni del processo di addestramento\n",
    "repeat = 10                             # numero di ripetizioni dopo le quali visualizzare l'errore\n",
    "model.reset_parameters()                # reinizializza i parametri della rete\n",
    "model.set_learning_rate(0.02)           # imposta il learning rate\n",
    "model.train(X, Y, num_epochs, repeat)   # addestra la rete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mettiamo in funzione la rete su un nuovo test set: se l'addestramento ha avuto successo, si dovrebbe ottenere un piccolo errore quadratico medio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** Inferenza ***\n",
      "x1\tx2\ty\ty prev\terrore\n",
      "2.40\t2.12\t2.26\t2.27\t-0.01\n",
      "3.92\t3.81\t3.87\t3.87\t-0.01\n",
      "2.31\t2.16\t2.23\t2.24\t-0.01\n",
      "-0.82\t-4.13\t-2.47\t-2.46\t-0.01\n",
      "-0.33\t3.95\t1.81\t1.82\t-0.01\n",
      "-4.64\t-0.13\t-2.38\t-2.37\t-0.01\n",
      "-3.99\t-2.20\t-3.10\t-3.08\t-0.02\n",
      "-0.87\t0.81\t-0.03\t-0.02\t-0.01\n",
      "-0.17\t-4.81\t-2.49\t-2.47\t-0.01\n",
      "1.99\t3.77\t2.88\t2.89\t-0.01\n",
      "Errore quadratico medio: 0.00014\n"
     ]
    }
   ],
   "source": [
    "model.predict(examples(10), fun)        # inferenza dopo l'addestramento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizziamo i valori dei parametri della rete: se l'addestramento ha avuto successo, dovrebbero essere vicini ai valori attesi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neuron.weight tensor([[0.4995, 0.4995]], device='cuda:0')\n",
      "neuron.bias tensor([0.0120], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "model.print_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D'altra parte, è evidente che un singolo neurone a comportamento lineare può approssimare efficacemente solo funzioni molto semplici. Anche aumentando il numero di esempi e di ripetizioni del processo di addestramento, per esempio non è in grado di approssimare in modo accettabile la funzione massimo tra due numeri."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** Addestramento ***\n",
      "epoca\terrore (su cuda)\n",
      "100\t1.515\n",
      "200\t1.452\n",
      "300\t1.451\n",
      "400\t1.451\n",
      "500\t1.451\n",
      "600\t1.451\n",
      "700\t1.451\n",
      "800\t1.451\n",
      "900\t1.451\n",
      "1000\t1.451\n",
      "\n",
      "*** Inferenza ***\n",
      "x1\tx2\ty\ty prev\terrore\n",
      "-0.74\t4.40\t4.40\t3.48\t0.92\n",
      "-2.14\t-0.06\t-0.06\t0.53\t-0.58\n",
      "-4.78\t0.56\t0.56\t-0.53\t1.09\n",
      "0.21\t-2.42\t0.21\t0.56\t-0.35\n",
      "3.96\t0.50\t3.96\t3.96\t-0.00\n",
      "-3.69\t2.05\t2.05\t0.77\t1.27\n",
      "3.48\t3.47\t3.48\t5.19\t-1.71\n",
      "3.68\t3.55\t3.68\t5.34\t-1.65\n",
      "-4.85\t2.13\t2.13\t0.22\t1.92\n",
      "-0.95\t-3.76\t-0.95\t-0.71\t-0.24\n",
      "Errore quadratico medio: 1.35233\n"
     ]
    }
   ],
   "source": [
    "num_examples = 1000                     # numero di esempi per il training set\n",
    "X = examples(num_examples)              # input del training set\n",
    "def fun(x1, x2): return torch.max(x1, x2) # funzione da approssimare, in questo caso il massimo tra due numeri\n",
    "Y = model.calc_fun(fun, X)              # calcola il valore della funzione per ogni esempio: output del training set\n",
    "num_epochs = 1000                       # numero di ripetizioni del processo di addestramento\n",
    "repeat = 100                            # numero di ripetizioni dopo le quali visualizzare l'errore\n",
    "model.reset_parameters()                # reinizializza i parametri della rete\n",
    "model.set_learning_rate(0.01)           # imposta il learning rate\n",
    "model.train(X, Y, num_epochs, repeat)   # addestra la rete\n",
    "model.predict(examples(10), fun)        # metti in funzione la rete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per ottenere approssimazioni accettabili occorre dunque costruire una rete più complessa."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
